---
title: Building a File Storage With Next.js, PostgreSQL, and Minio S3
description: In this article, we will build a full-stack application using Next.js, PostgreSQL, and Minio S3.
date: 2024-01-31
tags: [nextjs, react, postgres, minio, docker]
image: /blog-assets/file-storage-nextjs-postgres-s3/cover.png
thumbnail: /blog/nextjs-postgres-s3-locally/cover.png
---

# Building a file storage with Next.js, PostgreSQL, and Minio S3

![Building a file storage with Next.js, PostgreSQL, and Minio S3](/blog-assets/file-storage-nextjs-postgres-s3/cover.png)

It is the second part of the series of articles about building a file storage with Next.js, PostgreSQL, and Minio S3. In [the first part](http://blog.alexefimenko.com/posts/nextjs-postgres-s3-locally), we have set up the development environment using Docker Compose. In this part, we will build a full-stack application using Next.js, PostgreSQL, and Minio S3.

## Introduction

In the early days of web development, files like images and documents were stored on the web server along with the application code. However, with increasing user traffic and the need to store large files, cloud storage services like Amazon S3 have become the preferred way to store files.

Separating the storage of files from the web server provides several benefits, including:

- Scalability and performance
- Large file support (up to 5TB)
- Cost efficiency
- Separation of concerns

In this article, we will build an example of a file storage application using Next.js, PostgreSQL, and Minio S3. There are two main ways to upload files to S3 from Next.js:

1. Using API routes to upload and download files.
   This is a simpler approach, but it has a limitation of 4MB, if you try to upload file more than 4MB, you will get a Next.js error ["API Routes Response Size Limited to 4MB" Error in Next.js"](https://nextjs.org/docs/messages/api-routes-response-size-limit).

1. Using presigned URLs to get temporary access to upload files and then upload files directly from frontend to S3.
   This approach is a little bit more complex, but it does not use resources on the Next.js server with file uploads.

## Source Code

You can find the full source code for this tutorial on [GitHub](https://github.com/aleksandr-efimenko/local-nextjs-postgres-s3)

## Shared code for both approaches

Some code will be shared between the two approaches like UI components, database models, utility functions, and types.

### Upload form UI

To upload files, we will create a form with a file input field. `UploadFilesFormUI.tsx` will contain the UI for the upload form which will be used in both approaches. Here is a simplified version of the file:

```tsx filename="src/components/UploadFilesForm/UploadFilesFormUI.tsx" copy
import Link from 'next/link'
import { LoadSpinner } from '../LoadSpinner'
import { type UploadFilesFormUIProps } from '~/utils/types'

export function UploadFilesFormUI({ isLoading, fileInputRef, uploadToServer, maxFileSize }: UploadFilesFormUIProps) {
  return (
    <form className='flex flex-col items-center justify-center gap-3' onSubmit={uploadToServer}>
      <h1 className='text-2xl'>File upload example using Next.js, MinIO S3, Prisma and PostgreSQL</h1>
      {isLoading ? (
        <LoadSpinner />
      ) : (
        <div className='flex h-16 gap-5'>
          <input
            id='file'
            type='file'
            multiple
            className='rounded-md border bg-gray-100 p-2 py-5'
            required
            ref={fileInputRef}
          />
          <button
            disabled={isLoading}
            className='m-2 rounded-md bg-blue-500 px-5 py-2 text-white
                hover:bg-blue-600  disabled:cursor-not-allowed disabled:bg-gray-400'
          >
            Upload
          </button>
        </div>
      )}
    </form>
  )
}
```

### Database schema

To save information about the uploaded files, we will create a `File` model in the database. In the `schema.prisma` file, add the following model:

```prisma filename="prisma/schema.prisma" copy
model File {
    id           String   @id @default(uuid())
    bucket       String
    fileName     String   @unique
    originalName String
    createdAt    DateTime @default(now())
    size         Int
}
```

- id - the unique identifier of the file in the database generated by the uuid() function.
- bucket - the name of the bucket in S3 where the file is stored, in our case it will be the same for all files.
- fileName - the name of the file in S3, it will be unique for each file. If users upload files with the same name, the new file will overwrite the old one.
- originalName - the original name of the file that the user uploaded. We will use it to display the file name to the user when downloading the file.
- createdAt - the date and time when the file was uploaded.
- size - the size of the file in bytes.

After creating the model, we need to apply the changes to the database. We can do this using `db push` or `db migrate` command, the difference between the two commands is that `db push` will drop the database and recreate it, while `db migrate` will only apply the changes to the database. More information about the commands can be found in [Prisma docs](https://www.prisma.io/docs/orm/prisma-migrate/workflows/prototyping-your-schema#choosing-db-push-or-prisma-migrate). In our case it doesn't matter which command we use, so we will use `db push` command.

### Environment variables

If we use Docker Compose to run the application for testing and development, we can store environment variables in the compose file because there is no need to keep them secret. However, in production, we should store environment variables in a `.env`.
Here is an example of the `.env` file for AWS S3 and PostgreSQL. Replace the values with your own.

```env filename=".env" copy
DATABASE_URL="postgresql://postgres:postgres@REMOTESERVERHOST:5432/myapp-db?schema=public"

S3_ENDPOINT="s3.amazonaws.com"
S3_ACCESS_KEY="AKIAIOSFODNN7EXAMPLE"
S3_SECRET_KEY="wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
S3_BUCKET_NAME="my-bucket"
```

For using Google Cloud Storage, you can use the following environment variables:

```env filename=".env" copy
DATABASE_URL="postgresql://postgres:postgres@REMOTESERVERHOST:5432/myapp-db?schema=public"

S3_ENDPOINT="storage.googleapis.com"
S3_PORT="9000"
S3_ACCESS_KEY="GOOG1EEXAMPLEKEYDFDSDFSDKJFKLSDJFSLKSDJDSF"
S3_SECRET_KEY="wJDFJKSJDOIVMDSOIJFLKDSJkdDFiCYEXAMPLEKEY"
S3_BUCKET_NAME="my-bucket"

```

## Upload and download files using Next.js API routes (4MB limit)

![Upload and files using Next.js API route](/blog-assets/file-storage-nextjs-postgres-s3/API-route-upload-diagram.png)

The diagram above shows the steps involved in uploading and downloading files using Next.js API routes.

To upload files:

1. User sends a POST request to the API route with the file to upload.
2. The API route uploads the file to S3 and returns the file name.
3. The file name is saved in the database.

To download files:

1. User sends a GET request to the API route to get data from the database about the file(s) to download.
2. The API route downloads the file from S3.
3. The file is returned to the user from the API route.

### 1. Frontend

#### Upload form logic for API routes

We will create a `UploadFilesRoute.tsx` file with the logic for the upload form.

The algorithm for uploading files to the server is as follows:

1. The user selects files to upload, and the `fileInputRef` is updated with the selected files.
2. Form data is created from the selected files using the `createFormData` function and [FormData](https://developer.mozilla.org/en-US/docs/Web/API/FormData) API.
3. The form data is sent to the server using POST request to the `/api/files/upload/smallFiles` route.
4. The server uploads the files to S3 and returns status and message in the response.

It's usually a good idea to extract the logic of the UI component into a separate file. One way is to create hooks for the logic and use the hooks in the UI component, however, for simplicity, we will create a separate file for the logic "fileUploadHelpers.ts" and use it in the "UploadFilesRoute" component.

```tsx filename="src/utils/fileUploadHelpers.ts" copy
export function createFormData(files: File[]): FormData {
  const formData = new FormData()
  files.forEach((file) => {
    formData.append('file', file)
  })
  return formData
}
```

Here is a simplified version, without validation, loading state and error handling:

```tsx filename="src/components/UploadFilesForm/UploadFilesRoute.tsx" copy
import { useState, useRef } from 'react'
import { validateFiles, createFormData } from '~/utils/fileUploadHelpers'
import { MAX_FILE_SIZE_NEXTJS_ROUTE } from '~/utils/fileUploadHelpers'
import { UploadFilesFormUI } from './UploadFilesFormUI'

type UploadFilesFormProps = {
  onUploadSuccess: () => void
}

export function UploadFilesRoute({ onUploadSuccess }: UploadFilesFormProps) {
  const fileInputRef = useRef<HTMLInputElement | null>(null)

  const uploadToServer = async (event: React.FormEvent<HTMLFormElement>) => {
    event.preventDefault()

    const files = Object.values(fileInputRef.current?.files)

    const formData = createFormData(files)
    const response = await fetch('/api/files/upload/smallFiles', {
      method: 'POST',
      body: formData,
    })
    const body = (await response.json()) as {
      status: 'ok' | 'fail'
      message: string
    }
  }

  return (
    <UploadFilesFormUI
      isLoading={isLoading}
      fileInputRef={fileInputRef}
      uploadToServer={uploadToServer}
      maxFileSize={MAX_FILE_SIZE_NEXTJS_ROUTE}
    />
  )
}
```

Check the full code in the [GitHub repository](https://github.com/aleksandr-efimenko/local-nextjs-postgres-s3/blob/main/src/components/UploadFilesForm/UploadFilesRoute.tsx)

### 2. Backend

#### 2.1 Create utility functions to upload files using Minio S3

Since we are using Minio S3 as the storage service, we need to install the [Minio library](https://www.npmjs.com/package/minio) to interact with S3. This library is compatible with any S3-compatible storage service, including Amazon S3, Google Cloud Storage, and others.

Install the Minio library using the following command:

```bash
npm install minio
```

Then, let's create a utility functions to upload files to Minio S3. Personally, I prefer to create a separate file for utility functions, so I will create a file `s3-file-management.ts` in the `utils` folder.

```ts filename="src/utils/s3-file-management.ts" copy
import * as Minio from 'minio'
import type internal from 'stream'
import { env } from '~/env.js'

// Create a new Minio client with the S3 endpoint, access key, and secret key
export const s3Client = new Minio.Client({
  endPoint: env.S3_ENDPOINT,
  port: env.S3_PORT ? Number(env.S3_PORT) : undefined,
  accessKey: env.S3_ACCESS_KEY,
  secretKey: env.S3_SECRET_KEY,
  useSSL: env.S3_USE_SSL === 'true',
})

export async function createBucketIfNotExists(bucketName: string) {
  const bucketExists = await s3Client.bucketExists(bucketName)
  if (!bucketExists) {
    await s3Client.makeBucket(bucketName)
  }
}

export async function saveFileInBucket({
  bucketName,
  fileName,
  file,
}: {
  bucketName: string
  fileName: string
  file: Buffer | internal.Readable
}) {
  // Create bucket if it doesn't exist
  await createBucketIfNotExists(bucketName)

  // Upload image to S3 bucket
  await s3Client.putObject(bucketName, fileName, file)
}
```

If we want to check if the file exists in the bucket, we can create a function `

```ts filename="src/utils/s3-file-management.ts" copy
export async function checkFileExistsInBucket({ bucketName, fileName }: { bucketName: string; fileName: string }) {
  try {
    await s3Client.statObject(bucketName, fileName)
  } catch (error) {
    return false
  }
  return true
}
```

### References and Further Reading

[Upload files with NextJS + Fetch + Api routes + Typescript](https://devpress.csdn.net/react/62eb6bd020df032da732b2ea.html)
[Minio Docs](https://docs.min.io/docs/javascript-client-api-reference.html)
